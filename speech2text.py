import time
import torch
import numpy as np
import sounddevice as sd
from scipy.io.wavfile import write
from transformers import pipeline
from playsound import playsound
import speech_recognition as sr

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Thonburian Whisper
MODEL_NAME = "biodatlab/whisper-th-small-combined"
lang = "th"
device = 0 if torch.cuda.is_available() else "cpu"

pipe = pipeline(
    task="automatic-speech-recognition",
    model=MODEL_NAME,
    chunk_length_s=30,
    device=device,
)

WAKE_WORDS = ["‡πÄ‡∏°‡∏•", "Mel", "‡πÄ‡∏°‡πÇ‡∏•‡∏ô‡∏µ‡πà", "Melony", "‡πÄ‡∏°‡πÇ‡∏£‡∏ô‡∏µ‡πà", "‡πÄ‡∏°‡πÇ‡∏£‡∏ô‡∏µ", "‡πÄ‡∏°‡πÇ‡∏•‡∏ô‡∏µ", "Merony", "‡πÄ‡∏°‡πÇ‡∏£‡∏ô‡∏µ‡πà‡πâ", "‡πÄ‡∏°‡πÇ‡∏£‡∏ô‡∏µ‡πâ", "‡πÄ‡∏°‡πÇ‡∏•‡∏ô‡∏µ‡πâ", "‡πÄ‡∏°", "‡πÄ‡∏°‡∏ß", "mail"]

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏•‡πà‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô=
def play_beep(file_path):
    try:
        playsound(file_path)
    except Exception as e:
        print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏•‡πà‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á {file_path}: {e}")

# ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ "‡πÄ‡∏°‡∏•" ‡∏Å‡πà‡∏≠‡∏ô‡∏ñ‡∏∂‡∏á‡∏à‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ü‡∏±‡∏á
def detect_wake_word():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("üïµÔ∏è ‡∏£‡∏≠‡∏ü‡∏±‡∏á‡∏Ñ‡∏≥‡πÄ‡∏£‡∏µ‡∏¢‡∏Å... (‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤ '‡πÄ‡∏°‡∏•' ‡∏´‡∏£‡∏∑‡∏≠ 'Mel')")

        while True:
            try:
                audio = recognizer.listen(source, phrase_time_limit=3)
                text = recognizer.recognize_google(audio, language="th-TH").lower()
                for word in WAKE_WORDS:
                    if word.lower() in text:
                        print("üê± ‡πÑ‡∏î‡πâ‡∏¢‡∏¥‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏°‡∏•‡πÅ‡∏•‡πâ‡∏ß! ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ü‡∏±‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡πÄ‡∏°‡∏µ‡πä‡∏¢‡∏ß~")
                        return
            except sr.UnknownValueError:
                continue
            except Exception as e:
                print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö: {e}")
                continue

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏á‡∏µ‡∏¢‡∏ö
def record_audio_auto(filename="recorded.wav", samplerate=16000, silence_threshold=0.05, silence_duration=1.5):
    duration_limit = 30
    frame_duration = 0.1  # ‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡∏•‡∏∞ 100ms
    max_silent_chunks = int(silence_duration / frame_duration)

    sd.default.samplerate = samplerate
    sd.default.channels = 1

    frames = []
    silent_chunks = 0
    recording_started = False

    play_beep("assets/beep_sound/start_beep.wav")
    print("üî¥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏£‡∏≠‡∏ü‡∏±‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á... (‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏û‡∏π‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà‡πÄ‡∏°‡πÇ‡∏•‡∏ô‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏´‡πâ‡∏ô‡∏∞~)")

    with sd.InputStream() as stream:
        start_time = time.time()

        while True:
            frame, _ = stream.read(int(samplerate * frame_duration))
            volume = np.linalg.norm(frame)

            if volume > silence_threshold:
                if not recording_started:
                    print("üü¢ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡πâ‡∏ß~ ‡πÄ‡∏°‡∏µ‡πä‡∏¢‡∏ß~")
                    recording_started = True

                frames.append(frame)
                silent_chunks = 0
            else:
                if recording_started:
                    silent_chunks += 1
                    if silent_chunks > max_silent_chunks:
                        print("üîï ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏á‡∏µ‡∏¢‡∏ö~ ‡∏´‡∏¢‡∏∏‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏°‡∏µ‡πä‡∏¢‡∏ß~")
                        break

            if time.time() - start_time > duration_limit:
                print("‚è∞ ‡∏´‡∏°‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å~ ‡πÄ‡∏°‡∏µ‡πä‡∏¢‡∏ß~")
                break

    if frames:
        audio_data = np.concatenate(frames, axis=0)
        write(filename, samplerate, audio_data)
        play_beep("assets/beep_sound/end_beep.wav")
        print("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏°‡∏µ‡πä‡∏¢‡∏ß~")
    else:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ô‡∏∞‡πÄ‡∏°‡∏µ‡πä‡∏¢‡∏ß~")

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
def recognize_speech(audio_path="recorded.wav"):
    try:
        result = pipe(
            audio_path,
            generate_kwargs={"language": "<|th|>", "task": "transcribe"},
            batch_size=16
        )
        return result["text"]
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡∏ì‡∏∞‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á: {e}")
        return None

# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö standalone
if __name__ == "__main__":
    detect_wake_word()
    record_audio_auto()
    text = recognize_speech()
    print(f"üìù ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ: {text}")
